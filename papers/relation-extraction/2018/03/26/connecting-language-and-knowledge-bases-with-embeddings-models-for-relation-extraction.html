<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[Paper] Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</title>
  <meta name="description" content="Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/papers/relation-extraction/2018/03/26/connecting-language-and-knowledge-bases-with-embeddings-models-for-relation-extraction.html">
  <link rel="alternate" type="application/rss+xml" title="Tim Niven (寒山)" href="/feed.xml">
  
  
</head>


  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">Tim Niven (寒山)</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
          <a class="page-link" href="/publications/">Publications</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">[Paper] Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</h1>
    <p class="post-meta"><time datetime="2018-03-26T00:00:00+08:00" itemprop="datePublished">Mar 26, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="connecting-language-and-knowledge-bases-with-embedding-models-for-relation-extraction">Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</h1>

<p>Weston et al. (2013), ???</p>

<p>https://arxiv.org/pdf/1307.7973.pdf</p>

<h2 id="problem-and-solution">Problem and Solution</h2>

<ul>
  <li>Sub-task of Information Extraction: Relation Extraction, assuming the entities have already been identified</li>
  <li>For a relation mention $m$ including $(h, t)$ the task is to assign the appropriate relation from the KB</li>
  <li>“Weakly supervised” in the sense that all $m$ are associated with all existing links between $(h, t)$ already in the KB</li>
  <li>Novelty of this work is using the KB triples as well as the text to complete this task</li>
</ul>

<h2 id="details">Details</h2>

<p>Learn two models:</p>
<ul>
  <li>One for extracting relations</li>
  <li>One for patterns of relations in the KB</li>
</ul>

<p>Learning representations for:</p>
<ul>
  <li>Entities</li>
  <li>Relations</li>
  <li>Words in the vocabulary</li>
</ul>

<h3 id="extracting-relations">Extracting Relations</h3>

<p>Take the window of text around a mention $m$ and calculate a score for each relation</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
S_{m2r}(m, r) &= f(m)^\top r \\
              &= (W^\top \phi(m))^\top r
\end{align*} %]]></script>

<p>where</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
  f(m) &\in \Bbb{R}^k \\
  W &\in \Bbb{R}^{|V| \times k} \\
  r &\in \Bbb{R}^k \\
  m &\in \Bbb{R}^{|V|} \\
\end{align*} %]]></script>

<p>Given the task is weakly supervised, they use a ranking loss over the dataset $\mathcal{D} = {(m_i, r_i), i = 1, \dots , \lvert \mathcal{D} \rvert }$ as</p>

<script type="math/tex; mode=display">\forall i, \forall r' \neq r_i, f(m_i)^\top r_i \gt 1 + f(m_i)^\top r'</script>

<p>Then given a mention the relation is predicted by</p>

<script type="math/tex; mode=display">\hat{r}(m) = \arg \max_{r' \in \mathcal{R}} S_{m2r}(m, r')</script>

<p>But this is not sufficient for PR curve evaluation, in which case use</p>

<script type="math/tex; mode=display">\forall i, h, \forall r' \neq r_i, f(m_i)^\top r_i \gt 1 + f(mj)^\top r'</script>

<p>Hard constraints are enforced on embedding norms</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\forall i, \lVert W_i \rVert_2 &\le 1 \\
\forall j, \lVert r_j \rVert_2 &\le 1
\end{align*} %]]></script>

<h3 id="encoding-structured-data-of-kbs">Encoding Structured Data of KBs</h3>

<p>Score the plausibility of new entity relationships missing from Freebase. Learn vectors of entities and relations. Based on TransE model (I’ve written up elsewhere), which they write as</p>

<script type="math/tex; mode=display">S_{kb_ie}(h, r, t) = - \lVert h + r - t \rVert_2^2</script>

<p>They train a ranking loss over corruptions in all three positions of the relation.</p>

<p>At test time, recalibration of scores over pairs might be required - they therefore simplify to a function of the rank of $r$:</p>

<script type="math/tex; mode=display">\tilde{S}_{kb_ie}(h, r, t) = \phi \left( \sum_{r' \neq r} \delta(S_{kb_ie}(h, r, t) \gt S_{kb_ie}(h, r', t)) \right)</script>

<p>where</p>

<script type="math/tex; mode=display">% <![CDATA[
\phi(x) = \begin{cases} 1 &x = t \\ 0 &\text{otherwise} \end{cases} %]]></script>

<p>But I’m not clear what $\delta$ is, or how this function works.</p>

<h3 id="relation-extraction">Relation Extraction</h3>

<p>For all pairs of entities in the test set, collect all mentions $\mathcal{M}_{h,t}$ and score</p>

<script type="math/tex; mode=display">\hat{r}_{h, t} = \arg \max_{r \in \mathcal{R}} \sum_{m \in \mathcal{M}_{h,r}} S_{m2r}(m, r)</script>

<p>At this point the predicted relation could be $NA$, in which case this is returned. Otherwise agreement is sought with the KB and a composite score is calculated as</p>

<script type="math/tex; mode=display">S_{m2r + kb_ie}(h, \hat{r}_{h,t}, t) = \sum_{m \in \mathcal{M}_{h,t}} S_{m2r}(m, \hat{r}_{h,t}) + \tilde{S}_{kb_ie}(h, \hat{r}_{h,t}, t)</script>

<h2 id="background-knowledge-and-related-work">Background Knowledge and Related Work</h2>

<p>These all use weak supervision and only text</p>
<ul>
  <li>Craven et al. (1999) matched the Yeast Protein Database with PubMed abstracts</li>
  <li>Training open extractors based on Wikipedia infoboxes: Wu and Weld (2007, 2010)</li>
  <li>Large-scale IE projects: Banko et al. 2007, Carlson et al. 2010</li>
  <li>RE on Wikipedia with Freebase: Mintz et al. 20099</li>
  <li>Multi-instance learning frameworks: Riedel et al. 2010, Hoffman et al. 2011, Surdeanu et al. 2012</li>
</ul>

<p>More recent and perhaps more interesting</p>
<ul>
  <li>Riedel et al. 2013, jointly model KB and text relying on collaborative filtering</li>
</ul>

<p>Previous work connecting words and Wordnet</p>
<ul>
  <li>Bordes et al. 2012</li>
</ul>

<p>Scoring plausibility of new relationships between entities not in Freebase</p>
<ul>
  <li>Nickel et al. 2011</li>
  <li>Bordes et al. 201(1/2/3)</li>
</ul>

<h2 id="discussion">Discussion</h2>

<ul>
  <li>Where do you get pre-defined relationships from? WordNet? Or I suppose Freebase has a pre-defined set?</li>
</ul>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <!--<h2 class="footer-heading">Tim Niven (寒山)</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Tim Niven (寒山)
            
            </li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/timniven"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">timniven</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>I maintain this blog to share information pertaining to my research that may be of interest to others, as well as generally useful information I wish to make a note of.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
