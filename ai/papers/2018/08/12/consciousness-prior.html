<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[Paper] The Consciousness Prior</title>
  <meta name="description" content="Bengio (2017)">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/ai/papers/2018/08/12/consciousness-prior.html">
  <link rel="alternate" type="application/rss+xml" title="Tim Niven (寒山)" href="/feed.xml">
  
  
</head>


  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">Tim Niven (寒山)</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
          <a class="page-link" href="/publications/">Publications</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">[Paper] The Consciousness Prior</h1>
    <p class="post-meta"><time datetime="2018-08-12T00:00:00+08:00" itemprop="datePublished">Aug 12, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p><a href="https://arxiv.org/pdf/1709.08568">Bengio (2017)</a></p>

<h2 id="summary">Summary</h2>

<ul>
  <li>Consciousness as awareness of one’s thoughts</li>
  <li>This should be <em>low-dimensional</em>. Why? Conscious thought is limited to
“a few [handful of] concepts” at a time. We use these concepts to
form statements to base predictions and decisions upon. E.g., we
might see a paw print on a table and predict “a cat lives in this
house”. It is intuitive that this prediction would come from higher
level abstractions - a lower-dimensional <strong>abstract</strong> space and not
very high-dimensional pixel space.</li>
  <li>The <strong>representation RNN</strong> <script type="math/tex">F</script> can be thought of as the content of
almost the whole brain, apart from the weights, that summarizes recent
and past observations. It will yield a very high-dimensional
<strong>representation state</strong> <script type="math/tex">h_t</script> based on the current observed state
<script type="math/tex">s_t</script>:</li>
</ul>

<script type="math/tex; mode=display">h_t = F(s_t, h_{t-1})</script>

<ul>
  <li>The <strong>consciousness RNN</strong> <script type="math/tex">C</script> then yields the <strong>conscious state</strong>
<script type="math/tex">c_t</script>, a very low-dimensional vector, and is derived from an
attention mechanism over the representation state plus some noise
<script type="math/tex">z_t</script>:</li>
</ul>

<script type="math/tex; mode=display">c_t = C(h_t, c_{t-1}, z_t)</script>

<ul>
  <li>The addition of noise introduces randomness into the attention
mechanism, useful for exploring different options in thinking - e.g.
different interpretations, different plans of action, different
predictions about the future.</li>
  <li>For training objectives in general we want to capture the idea that
these high-level features are useful for prediction and action.
Focusing on prediction, a <strong>verifier network</strong> measures the
consistency between a current representation state and a past
conscious state:</li>
</ul>

<script type="math/tex; mode=display">V(h_t, c_{t-k}) \in \mathbb{R}</script>

<ul>
  <li>Since the conscious state attends to some feature locations in the
representation state, it will be useful to know which ones they are.
For this reason a “key, value” system could be useful. This will be
vital for the verifier network to align the predictions with the
representation state.</li>
  <li>There is a mapping from conscious states to language utterances. But
the mapping in the other direction is underdetermined - it is
postulated that the conscious state is richer. This apts with my own
experience - an utterance sets off many of my own internal
associations, enthymeme fillers, etc. It also apts with the fact that
the same utterance can be interpreted in different ways - context
matters.</li>
  <li>It is therefore suggested as a regularization term that the attended
elements of the conscious states be mappable to already heard phrases
or words. This in turn implies that the representation states
<script type="math/tex">h_t</script> be regularized by language, that their features be mappable
roughly to words or short phrases.</li>
  <li>It follows from this that language facilitates thinking and
understanding - a point I am well on board with - that language helps
us build sharper internal representations, more disentangled, which
helps us learn better, and enable collaborative taslk solving.
References to follow this idea: Bengio et al. (2009) “Curriculum
learning”; Bengio (2014) “Deep learning and cultural evolution”.</li>
  <li>It would be of benefit to interprebility if a network could map its
abstract space to utterances, as it could then explain its decisions.</li>
</ul>

<h2 id="concerns">Concerns</h2>

<ul>
  <li>Given the variety of phenomena that can come into consciousness, I was
originally struggling to see how a low-dimensional space could handle
everything required of it. If it is instead thought of as simply
attending to a handful of dimensions in the representation space then
that makes more sense. However I am still struggling to conceive
how this works.</li>
  <li>It would be nice to see some concrete examples.</li>
</ul>

<h2 id="of-personal-interest">Of Personal Interest</h2>

<ul>
  <li>Andreas et al. (2017) “Learning with Latent Language” of related
interest.</li>
  <li>The idea of a thinking network might help me scratch the itch I’ve had
for a long time wondering about Eureka moments. Suppose the agent goes
into thinking mode to solve a problem. It can explore (with some
randomness) possibilities until it finds one that solves its problem.
How that would actually work algorithmically I don’t know, but at
least this architecture allows it to happen. Perhaps this idea may
connect with Schmidhuber’s work on fast and slow memory updates. I
encounter some input that jars with my world model, so I try and
resolve the issue through thinking - when I find a solution I can make
a fast update to my world model. (That really is idealistic, but AI
can do better than humans). Perhaps Charles Yang’s work from the NAACL
keynote could be a nice toy task to test this? I would also like to
use this for supervised learning - have a mechanism that picks out
<strong>salient examples</strong> from the training data - i.e. ones that are
challenging or provide the most opportunity for learning given the
current state of the network (maybe the worst misclassifications) -
commits them to memory, and can use them later in this kind of
“thinking -&gt; Eureka -&gt; fast update” process.</li>
  <li>Regarding my CCQ project: it could be worth keeping the original form
of the questions for a time when networks do have the ability to
answer questions in language mapped from their internal states.
However the question of evaluating the answers would remain a problem.</li>
</ul>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <!--<h2 class="footer-heading">Tim Niven (寒山)</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Tim Niven (寒山)
            
            </li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/timniven"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">timniven</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>I maintain this blog to share information pertaining to my research that may be of interest to others, as well as generally useful information I wish to make a note of.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
