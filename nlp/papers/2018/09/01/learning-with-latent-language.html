<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[Paper] Learning with Latent Language</title>
  <meta name="description" content="Andreas et al. NAACL 2018">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/nlp/papers/2018/09/01/learning-with-latent-language.html">
  <link rel="alternate" type="application/rss+xml" title="Tim Niven (寒山)" href="/feed.xml">
  
  
</head>


  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">Tim Niven (寒山)</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
          <a class="page-link" href="/publications/">Publications</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">[Paper] Learning with Latent Language</h1>
    <p class="post-meta"><time datetime="2018-09-01T00:00:00+08:00" itemprop="datePublished">Sep 1, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p><a href="https://arxiv.org/abs/1711.00482">Andreas et al. NAACL 2018</a></p>

<h2 id="problem">Problem</h2>

<p>The efficient automatic discovery of abstract structure.
Think few-shot learning.</p>

<p>“We seek an intermediate language of task representations that, like
in program synthesis, is both expressive and compact, but like in
multitask approaches is learnable directly from training data without
domain engineering.</p>

<h2 id="solution">Solution</h2>

<p>Use language as a latent <em>parameter space</em> for few-shot learning.</p>

<p>“The structure of natural language reflects the structure of the world.”
Language tells us about the kinds of abstractions that we find useful
for interpreting and navigating our environment.</p>

<p>“Our thesis is that language is a powerful, general-purpose kind of
pre-training, even for tasks that do not directly involve language.”
Natural language hypotheses mean</p>
<ul>
  <li>easier to discover compositional concepts in the training examples</li>
  <li>harder to overfit to few examples</li>
  <li>easier to understand inferred patterns</li>
</ul>

<p>By “equipping models with the ability to think out loud when learning
they become both more comprehensible and more accurate.”</p>

<p>Natural langauge:</p>
<ul>
  <li>is discrete</li>
  <li>has a rich set of compositional operators</li>
  <li>comes equipped with a natural description length prior</li>
  <li>flexible semantics</li>
  <li>plenty of annotated data exists for learning from language</li>
  <li>provides a strong prior about the kinds of abstractions that are
useful for natural learning problems</li>
</ul>

<h2 id="details">Details</h2>

<h3 id="generic-approach">Generic Approach</h3>

<p>Three stages:</p>

<h4 id="1-language-learning">1. Language Learning</h4>

<p>The <strong>language learning</strong> phase using different datasets <script type="math/tex">i</script>.
The datasets have samples like <script type="math/tex">\{ (\mathbf{x}_1^{(li)},
\mathbf{w}_1^{(li)}, y_1^{(li)}), \dots, (\mathbf{x}_n^{(li)},
\mathbf{w}_1^{(li)}, y_n^{(li)}) \}</script>.
The idea is to turn the tokens <script type="math/tex">\mathbf{w}^{(li)}</script> into a function
<script type="math/tex">f(\mathbf{x}, \mathbf{\eta}, y)</script> mapping from inputs
<script type="math/tex">\mathbf{x}^{(li)}</script> to outputs <script type="math/tex">y^{(li)}</script>.
For example an image rating model that gives a scalar value
<script type="math/tex">y^{(li)}</script> indicating how well a natural language description
<script type="math/tex">\mathbf{w}^{(li)}</script> matches an image <script type="math/tex">\mathbf{x}^{(li)}</script>.
They call this function a <strong>language interpretation model</strong>.
The job in this phase is to learn the real-valued parameters
<script type="math/tex">\mathbf{\eta}</script></p>

<script type="math/tex; mode=display">\arg \max_{\mathbf{\eta} \in \Bbb{R}^a}
\sum_{i, j}
L \left(
  f(\mathbf{x}_j^{(li)}; \mathbf{\eta}, \mathbf{w}^{(li)}),
  y_j^{(li)}
\right)</script>

<h4 id="2-concept-learning">2. Concept Learning</h4>

<p>The <strong>concept learning</strong> basically trains to a specific target dataset
with samples <script type="math/tex">\{ (\mathbf{x}_1^{(c)}, y_1^{(c)}), \dots,
(\mathbf{x}_n^{(c)}, y_n^{(c)}) \}</script>. This is now <strong>an optimization
problem over natural language strings</strong>:</p>

<script type="math/tex; mode=display">\arg \max_{\mathbf{w}' \in \Sigma*}
\sum_j
L \left(
  f(\mathbf{x}_j^{(c)}; \mathbf{\eta}, \mathbf{w}^{(c)}),
  y_j^{(c)}
\right)</script>

<p>This is an unusual optimization problem for me.
They propose to fit a <strong>reverse proposal model</strong> estimating</p>

<script type="math/tex; mode=display">\arg \max_\lambda \log q(\mathbf{w}_i|\mathbf{x}_1^{(li)}, y_1^{(li)},
\dots, \mathbf{x}_n^{(li)}, y_n^{(li)}; \lambda)</script>

<p>This <script type="math/tex">q</script> gives a distribution over strings expressing how likely they
are to be a match given the input data. They say it’s an image
captioning model in practice.</p>

<p>They sample from this distribution and perform optimization over the
resulting set of candidate strings <script type="math/tex">\Sigma*</script> that are expected to
obtain small loss.</p>

<h4 id="3-evaluation">3. Evaluation</h4>

<p>Apply learned concept to new input <script type="math/tex">\mathbf{x}^{(e)}</script> to obtain
prediction <script type="math/tex">y^{(e)}</script>. This is done by drawing a fixed number of
sample strings, find the one that achieves minimum loss, and then use
<script type="math/tex">f(\mathbf{x}^{(e)}; \mathbf{\eta}, \mathbf{w}^{(c)})</script> to make the
prediction.</p>

<h3 id="details-of-their-approach">Details of their Approach</h3>

<h4 id="few-shot-classification">Few-Shot Classification</h4>

<p>The learner sees four images which are positive examples of some visual
concept - e.g. “a red circle above a blue square” - and must decide if
a fifth held-out image matches the same concept.</p>

<p>The <strong>interpretation model</strong> is implemented as a VGGNet that encodes
the image, and an RNN encoder for descriptions</p>

<script type="math/tex; mode=display">f(\mathbf{x}, \mathbf{w}) = \sigma(\text{rnn-encode}(\mathbf{w})^\top
\text{rep}(\mathbf{x}))</script>

<p>which outputs a probability that the image matches the description and
is trained using maximum log-likelihood.</p>

<p>Their <strong>proposal model</strong> is defined as</p>

<script type="math/tex; mode=display">q(\mathbf{w}|\{\mathbf{x}_j\}) = \text{rnn-decode}(\mathbf{w} | \frac1n
\sum_j \text{rep}(\mathbf{x}_j))</script>

<p>They want to answer</p>
<ol>
  <li>Does the addition of language help as compared to multi-task or
meta-learning?</li>
  <li>It is better to use language as a hypothesis space or as additional
supervision?</li>
</ol>

<p>In the few-shot setting they answer (1) by comparing to MTL and ML
models. But I am not sure how to evaluate it as a comparison right
now. I will have to come back after learning more about multi-task and
meta-learning.</p>

<h4 id="programming-by-demonstration">Programming by Demonstration</h4>

<p>See five string transformations and have to apply the same to a sixth
input. There is also a natural language description of the
transformation.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\text{rep}(x, y) &= \text{rnn-encode}([x, y]) \\
f(y | x; w) &= \text{rnn_decode} \left( y | \text{rnn-encode}(x), \text{rnn-encode}(w)] \right) \\
q(w | \{(x_j, y_j)\}) &= \text{rnn-decode} \left( w | \frac1n \sum_j \text{rep}(x_j, y_j) \right)
\end{align*} %]]></script>

<p>Results:</p>
<ul>
  <li>They compare using regular expressions to using natural language and
find natural language superior. They hypothesize this is due to the
extra variation in natural language helping the model figure out the
true axes of variation and avoid overfitting</li>
  <li>Providing ground truth annotations was worse than letting the model
perform inference on its own. They hypothesize this is due to the
model being more reliable than the human annotators who sometimes
write, e.g., “I don’t know”.</li>
</ul>

<h4 id="reinforcement-learning">Reinforcement Learning</h4>

<p>The task is treasure hunting where the treasure is in some location a
fixed distance from some landmark. These are randomized over episodes.
Nothing in the agent’s observations should suggest these things are
related - but for the natural language descriptions.</p>

<p>The goal is to adapt quickly to new environments. The hypothesis is that
from the beginning, instead of searching in random parameter space,
which often leads to nonsensical behaviour, searching in the space of
natural language strings will at least lead to some reasonable policy,
which should in turn lead to faster learning. I find that very
compelling.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\text{rep}(x) &= \tanh(\text{fc}(\tanh(\text{fc}(x)))) \\
f(a| x; w) &\propto \text{rnn-encode}(w)^\top W_a \text{rep}(x) \\
q(w) &= \text{rnn-decode}(w)
\end{align*} %]]></script>

<p>At language learning time it is assumed to have natural language
descriptions of the target locations provided by human annotators and
expert policies for navigating there.</p>

<p>Learning proceeds by:</p>
<ul>
  <li>sampling a fixed number of descriptions <script type="math/tex">w</script> from <script type="math/tex">q</script></li>
  <li>for each, rollout the policy induced and estimate average reward</li>
  <li>take highest scoring description and perform further fine-tuning</li>
</ul>

<p>At language learning time the agent has access to 250 environments and
is evaluated on a further 50.</p>

<p>Results indeed show faster learning and “show that the model has used
the structure provided by language to <em>learn</em> a better representation
space for policies - one that allows it to sample from a distribution
over interesting and meaningful behaviors rather than sequences of
random actions.”</p>

<h2 id="datasets">Datasets</h2>

<p>ShapeWorld</p>
<ul>
  <li>Kuhnle and Copestake (2017)</li>
</ul>

<p>Their own string editing dataset.</p>

<p>Adaptation of a natural language navigation dataset</p>
<ul>
  <li>Janner et al. (2017)</li>
</ul>

<h2 id="background-and-related-work">Background and Related Work</h2>

<p>Inductive program synthesis approaches reduce the hypothesis space by
moving the problem out of continuous space and into the discrete space
of program descriptors</p>
<ul>
  <li>Gulwani (2011)</li>
  <li>version space algebras: Lau et al. 2003</li>
  <li>type systems: Kitzelmann and Schmid (2006)</li>
</ul>

<p>But the computational primitives necessary to describe every hypothesis
must be specified by hand a priori by a human designer.</p>

<p>Multi-task learning</p>
<ul>
  <li>Caruana (1998)</li>
</ul>

<p>Meta-learning</p>
<ul>
  <li>Schmidhuber (1987)</li>
  <li>Santoro et al. (2016)</li>
  <li>Vinyals et al. (2016)</li>
</ul>

<p>Image rating model</p>
<ul>
  <li>Socher et al. (2014)</li>
</ul>

<p>Techniques aimed at making synthesis more efficient</p>
<ul>
  <li>Devlin et al. (2017)</li>
</ul>

<p>Image captioning model</p>
<ul>
  <li>Donahue et al. (2015)</li>
</ul>

<p>Visual reasoning problems where a natural language explanation must be
inferred</p>
<ul>
  <li>Raven (1936)</li>
  <li>Bongard (1968)</li>
</ul>

<p>Visual question answering</p>
<ul>
  <li>Johnson et al. (2017)</li>
  <li>Suhr et al. (2017)</li>
</ul>

<p>Similar ideas to the RL task, in the context of human concept learning</p>
<ul>
  <li>Hermer-Vazquez et al. (2001)</li>
</ul>

<p>Instruction following model of a kind well studied in the NLP literature</p>
<ul>
  <li>Branavan et al. (2009)</li>
</ul>

<p>DAgger</p>
<ul>
  <li>Ross et al. (2011)</li>
</ul>

<p>Policy gradients</p>
<ul>
  <li>Williams (1992)</li>
</ul>

<p>Using natural language annotations to guide the discovery of logical
descriptions of concepts</p>
<ul>
  <li>Ling et al. (2017)</li>
  <li>Srivastava et al. (2017)</li>
</ul>

<p>Using structured language-like annotations to improve learning of
generalizable structured policies</p>
<ul>
  <li>Andreas et al. (2017)</li>
  <li>Denil et al. (2017)</li>
</ul>

<p>Using natural language at concept learning time for RL agents for</p>
<ul>
  <li>high level structure: Branavan et al. (2011)</li>
  <li>environment dynamics: Narasimhan et al. (2017)</li>
  <li>exploration: Harrison et al. (2017)</li>
</ul>

<p>Dataset augmentation strategy used in Navigation and Regex datasets</p>
<ul>
  <li>Jia and Liang (2016)</li>
</ul>

<p>Automatic template induction system (again data augmentation)</p>
<ul>
  <li>Kwiakowski et al. (2011)</li>
</ul>

<h2 id="discussion">Discussion</h2>

<ul>
  <li>Via their comparisons they make the case that this is a feasible
technique, which is very interesting. However, I have not seen any
specific discussion of they hypothesis that the performance increase
is due to discovery of compositional concepts. It is a tantalizing
hypothesis and I would like more said, or more investigation into
this aspect (unless I have missed it). Insofar as it is discussed it
seems to be a given from the nature of language itself. It would be
nice to see examples of learned behavior demonstrating this.</li>
  <li>The vocabulary used in these datasets is very small (see appendix).
This work is meant to be an initial exploration on smaller, toy tasks,
which I am totally on board with. But of course the next step is to
wonder how it could work with much larger and more complicated
natural language. Will their particular techniques be scalable? Have
we the datasets to do it?</li>
  <li>It seems the same function <script type="math/tex">f(x, \eta, w)</script> is used at both language
and concept learning time. It feels like this is restricting - it
seems the problems need to be the same, because the parameters are
the same. E.g., if as in the example we have a model rating how well
an image matches a description, how do we then use that for the
regex task? We are mapping from an image to a scalar in the first
case - that is what <script type="math/tex">\eta</script> has learned to do. It doesn’t seem like
we can then use the same function for a different task.</li>
  <li>How can we generalize if we don’t have a complete set of natural
language strings at language learning time?</li>
  <li>Relatedly, I am thinking about Bengio’s Consciousness Prior, wherein
he argued convincingly in my view for the benefits of having hidden
units mapped to words or phrases. The idea here seems to be somewhat
different, although some of the motivations align a little bit. I
don’t think this paper qualifies as progress towards Bengio’s idea,
but does further demonstrate that it is a good one.</li>
  <li>It also seems that the optimization step over natural language strings
is not ideal.</li>
  <li>I am also thinking about recent work I’ve read (and must review) about
learning a more explicit space using words…</li>
</ul>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <!--<h2 class="footer-heading">Tim Niven (寒山)</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Tim Niven (寒山)
            
            </li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/timniven"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">timniven</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>I maintain this blog to share information pertaining to my research that may be of interest to others, as well as generally useful information I wish to make a note of.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
